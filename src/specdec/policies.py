"""
Acceptance Policies for Speculative Decoding

This module implements various acceptance policies that determine how many
proposed tokens from the draft model should be accepted by the base model.
"""

import logging
from abc import ABC, abstractmethod
from typing import Any, Dict, Optional, Tuple

import torch

# Import kernels with fallback
try:
    from kernels import get_kernel_info, get_verify_prefix

    KERNELS_AVAILABLE = True
except ImportError:
    logger = logging.getLogger(__name__)
    logger.warning("Kernels not available, using fallback implementation")
    KERNELS_AVAILABLE = False

    def get_verify_prefix(device):
        return None

    def get_kernel_info():
        return {"verify_backend": "fallback"}


logger = logging.getLogger(__name__)


class AcceptancePolicy(ABC):
    """Abstract base class for acceptance policies."""

    @abstractmethod
    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """
        Determine how many proposed tokens to accept.

        Args:
            proposed_tokens: Tokens proposed by draft model [batch_size, seq_len]
            base_tokens: Tokens generated by base model [batch_size, seq_len]
            proposed_logits: Logits from draft model [batch_size, seq_len, vocab_size]
            base_logits: Logits from base model [batch_size, seq_len, vocab_size]
            **kwargs: Additional policy-specific parameters

        Returns:
            Tuple of (accepted_length, policy_info)
            - accepted_length: Number of tokens to accept
              (0 to proposed_tokens.shape[1])
            - policy_info: Dictionary with policy-specific information
        """
        pass

    @abstractmethod
    def get_info(self) -> Dict[str, Any]:
        """
        Get policy-specific information for logging and results.

        Returns:
            Dictionary with policy-specific information
        """
        pass


class LongestPrefixPolicy(AcceptancePolicy):
    """Default policy: accept the longest matching prefix."""

    def __init__(self):
        self.name = "longest_prefix"
        self.kernels_available = KERNELS_AVAILABLE
        self.kernel_info = (
            get_kernel_info() if KERNELS_AVAILABLE else {"verify_backend": "fallback"}
        )

    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """Accept the longest matching prefix of tokens."""
        # Try to use kernel if available and on CUDA
        if (
            self.kernels_available
            and base_logits is not None
            and base_logits.device.type == "cuda"
        ):

            try:
                # Get kernel for current device
                verify_kernel = get_verify_prefix(base_logits.device.type)
                if verify_kernel is not None:
                    # Use kernel for verification
                    accept_len, accepted_mask = verify_kernel(
                        base_logits, proposed_tokens
                    )
                    accepted_len = accept_len[0].item()  # Assuming batch size 1

                    return accepted_len, {
                        "policy": self.name,
                        "accepted_len": accepted_len,
                        "proposed_len": proposed_tokens.shape[1],
                        "base_len": base_tokens.shape[1],
                        "verify_backend": self.kernel_info["verify_backend"],
                    }
            except Exception as e:
                logger.warning(
                    f"Kernel verification failed, falling back to PyTorch: {e}"
                )

        # Fallback to PyTorch implementation
        # Use base_logits.argmax() for consistent verification (matches kernel path)
        # This ensures we're comparing the base model's predicted tokens (argmax) with draft tokens
        if base_logits is not None:
            # Get predicted tokens from base logits (argmax)
            # base_logits shape: [batch, seq_len, vocab_size]
            # We only need the first K positions where K = proposed_tokens.shape[1]
            base_predicted = torch.argmax(
                base_logits[:, : proposed_tokens.shape[1], :], dim=-1
            )  # [batch, K]

            # Ensure both tensors are on same device and dtype for comparison
            proposed_tokens_aligned = proposed_tokens.long()
            base_predicted_aligned = base_predicted.long()

            # Compare sequences position by position
            max_len = min(
                proposed_tokens_aligned.shape[1], base_predicted_aligned.shape[1]
            )
            accepted_len = 0

            for i in range(max_len):
                if torch.equal(
                    proposed_tokens_aligned[:, i], base_predicted_aligned[:, i]
                ):
                    accepted_len = i + 1
                else:
                    break
        else:
            # If no logits available, fall back to token comparison (less accurate)
            max_len = min(proposed_tokens.shape[1], base_tokens.shape[1])
            accepted_len = 0

            # Ensure same dtype for comparison
            proposed_tokens_aligned = proposed_tokens.long()
            base_tokens_aligned = base_tokens.long()

            for i in range(max_len):
                if torch.equal(
                    proposed_tokens_aligned[:, i], base_tokens_aligned[:, i]
                ):
                    accepted_len = i + 1
                else:
                    break

        return accepted_len, {
            "policy": self.name,
            "accepted_len": accepted_len,
            "proposed_len": proposed_tokens.shape[1],
            "base_len": base_tokens.shape[1],
            "verify_backend": "torch",
        }

    def get_info(self) -> Dict[str, Any]:
        """Get policy information."""
        return {
            "policy": self.name,
        }


class ConfidenceThresholdPolicy(AcceptancePolicy):
    """Accept tokens based on confidence threshold."""

    def __init__(self, tau: float = 0.5):
        """
        Initialize confidence threshold policy.

        Args:
            tau: Confidence threshold (0.0 to 1.0)
        """
        self.tau = tau
        self.name = "conf_threshold"

    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """Accept tokens based on confidence threshold."""
        if proposed_logits is None:
            # Fallback to longest prefix if no logits available
            policy = LongestPrefixPolicy()
            return policy.accept_tokens(proposed_tokens, base_tokens)

        # Calculate confidence scores (softmax probabilities)
        probs = torch.softmax(proposed_logits, dim=-1)
        max_probs = torch.max(probs, dim=-1)[0]  # [batch_size, seq_len]

        # Find where confidence drops below threshold
        accepted_len = 0
        for i in range(proposed_tokens.shape[1]):
            if max_probs[0, i] >= self.tau:
                accepted_len = i + 1
            else:
                break

        return accepted_len, {
            "policy": self.name,
            "tau": self.tau,
            "accepted_len": accepted_len,
            "proposed_len": proposed_tokens.shape[1],
            "min_confidence": (
                float(torch.min(max_probs[0, :accepted_len]))
                if accepted_len > 0
                else 0.0
            ),
        }

    def get_info(self) -> Dict[str, Any]:
        """Get policy information."""
        return {
            "policy": self.name,
            "tau": self.tau,
        }


class TopKAgreementPolicy(AcceptancePolicy):
    """Accept tokens where top-k predictions agree."""

    def __init__(self, k: int = 5):
        """
        Initialize top-k agreement policy.

        Args:
            k: Number of top predictions to consider
        """
        self.k = k
        self.name = "topk_agree"

    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """Accept tokens where top-k predictions agree."""
        if proposed_logits is None or base_logits is None:
            # Fallback to longest prefix if no logits available
            policy = LongestPrefixPolicy()
            return policy.accept_tokens(proposed_tokens, base_tokens)

        # Get top-k predictions for both models
        base_topk = torch.topk(base_logits, self.k, dim=-1)[
            1
        ]  # [batch_size, seq_len, k]

        # Check agreement for each position
        accepted_len = 0
        for i in range(proposed_tokens.shape[1]):
            # Check if proposed token is in base model's top-k
            proposed_token = proposed_tokens[0, i]
            base_topk_tokens = base_topk[0, i, :]

            if proposed_token in base_topk_tokens:
                accepted_len = i + 1
            else:
                break

        return accepted_len, {
            "policy": self.name,
            "k": self.k,
            "accepted_len": accepted_len,
            "proposed_len": proposed_tokens.shape[1],
        }

    def get_info(self) -> Dict[str, Any]:
        """Get policy information."""
        return {
            "policy": self.name,
            "k": self.k,
        }


class TypicalAcceptancePolicy(AcceptancePolicy):
    """Accept tokens based on typical acceptance probability."""

    def __init__(self, p: float = 0.9):
        """
        Initialize typical acceptance policy.

        Args:
            p: Typical acceptance probability (0.0 to 1.0)
        """
        self.p = p
        self.name = "typical"

    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """Accept tokens based on typical acceptance probability."""
        if proposed_logits is None or base_logits is None:
            # Fallback to longest prefix if no logits available
            policy = LongestPrefixPolicy()
            return policy.accept_tokens(proposed_tokens, base_tokens)

        # Calculate typical acceptance probability
        torch.softmax(proposed_logits, dim=-1)
        base_probs = torch.softmax(base_logits, dim=-1)

        # Calculate typical acceptance for each position
        accepted_len = 0
        for i in range(proposed_tokens.shape[1]):
            # Get probability of proposed token in base model
            proposed_token = proposed_tokens[0, i]
            base_prob = base_probs[0, i, proposed_token]

            # Accept if probability is above typical threshold
            if base_prob >= self.p:
                accepted_len = i + 1
            else:
                break

        return accepted_len, {
            "policy": self.name,
            "p": self.p,
            "accepted_len": accepted_len,
            "proposed_len": proposed_tokens.shape[1],
            "min_probability": (
                float(
                    torch.min(
                        base_probs[0, :accepted_len, proposed_tokens[0, :accepted_len]]
                    )
                )
                if accepted_len > 0
                else 0.0
            ),
        }

    def get_info(self) -> Dict[str, Any]:
        """Get policy information."""
        return {
            "policy": self.name,
            "p": self.p,
        }


def create_policy(policy_name: str, **kwargs: Any) -> AcceptancePolicy:
    """
    Create an acceptance policy by name.

    Args:
        policy_name: Name of the policy to create
        **kwargs: Policy-specific parameters

    Returns:
        AcceptancePolicy instance

    Raises:
        ValueError: If policy_name is not recognized
    """
    policies = {
        "longest_prefix": LongestPrefixPolicy,
        "conf_threshold": lambda: ConfidenceThresholdPolicy(kwargs.get("tau", 0.5)),
        "topk_agree": lambda: TopKAgreementPolicy(kwargs.get("k", 5)),
        "typical": lambda: TypicalAcceptancePolicy(kwargs.get("p", 0.9)),
    }

    if policy_name not in policies:
        raise ValueError(
            f"Unknown policy: {policy_name}. Available: {list(policies.keys())}"
        )

    return policies[policy_name]()
