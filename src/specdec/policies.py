"""
Acceptance Policies for Speculative Decoding

This module implements various acceptance policies that determine how many
proposed tokens from the draft model should be accepted by the base model.
"""

import logging

from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, Tuple

import torch

logger = logging.getLogger(__name__)


class AcceptancePolicy(ABC):
    """Abstract base class for acceptance policies."""

    @abstractmethod
    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """
        Determine how many proposed tokens to accept.

        Args:
            proposed_tokens: Tokens proposed by draft model [batch_size, seq_len]
            base_tokens: Tokens generated by base model [batch_size, seq_len]
            proposed_logits: Logits from draft model [batch_size, seq_len, vocab_size]
            base_logits: Logits from base model [batch_size, seq_len, vocab_size]
            **kwargs: Additional policy-specific parameters

        Returns:
            Tuple of (accepted_length, policy_info)
            - accepted_length: Number of tokens to accept
              (0 to proposed_tokens.shape[1])
            - policy_info: Dictionary with policy-specific information
        """
        pass


class LongestPrefixPolicy(AcceptancePolicy):
    """Default policy: accept the longest matching prefix."""

    def __init__(self):
        self.name = "longest_prefix"

    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """Accept the longest matching prefix of tokens."""
        # Find the longest matching prefix
        max_len = min(proposed_tokens.shape[1], base_tokens.shape[1])
        accepted_len = 0

        for i in range(max_len):
            if torch.equal(proposed_tokens[:, i], base_tokens[:, i]):
                accepted_len = i + 1
            else:
                break

        return accepted_len, {
            "policy": self.name,
            "accepted_len": accepted_len,
            "proposed_len": proposed_tokens.shape[1],
            "base_len": base_tokens.shape[1],
        }

    def get_info(self) -> Dict[str, Any]:
        """Get policy information."""
        return {
            "policy": self.name,
        }


class ConfidenceThresholdPolicy(AcceptancePolicy):
    """Accept tokens based on confidence threshold."""

    def __init__(self, tau: float = 0.5):
        """
        Initialize confidence threshold policy.

        Args:
            tau: Confidence threshold (0.0 to 1.0)
        """
        self.tau = tau
        self.name = "conf_threshold"

    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """Accept tokens based on confidence threshold."""
        if proposed_logits is None:
            # Fallback to longest prefix if no logits available
            policy = LongestPrefixPolicy()
            return policy.accept_tokens(proposed_tokens, base_tokens)

        # Calculate confidence scores (softmax probabilities)
        probs = torch.softmax(proposed_logits, dim=-1)
        max_probs = torch.max(probs, dim=-1)[0]  # [batch_size, seq_len]

        # Find where confidence drops below threshold
        accepted_len = 0
        for i in range(proposed_tokens.shape[1]):
            if max_probs[0, i] >= self.tau:
                accepted_len = i + 1
            else:
                break

        return accepted_len, {
            "policy": self.name,
            "tau": self.tau,
            "accepted_len": accepted_len,
            "proposed_len": proposed_tokens.shape[1],
            "min_confidence": (
                float(torch.min(max_probs[0, :accepted_len]))
                if accepted_len > 0
                else 0.0
            ),
        }

    def get_info(self) -> Dict[str, Any]:
        """Get policy information."""
        return {
            "policy": self.name,
            "tau": self.tau,
        }


class TopKAgreementPolicy(AcceptancePolicy):
    """Accept tokens where top-k predictions agree."""

    def __init__(self, k: int = 5):
        """
        Initialize top-k agreement policy.

        Args:
            k: Number of top predictions to consider
        """
        self.k = k
        self.name = "topk_agree"

    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """Accept tokens where top-k predictions agree."""
        if proposed_logits is None or base_logits is None:
            # Fallback to longest prefix if no logits available
            policy = LongestPrefixPolicy()
            return policy.accept_tokens(proposed_tokens, base_tokens)

        # Get top-k predictions for both models
        base_topk = torch.topk(base_logits, self.k, dim=-1)[
            1
        ]  # [batch_size, seq_len, k]

        # Check agreement for each position
        accepted_len = 0
        for i in range(proposed_tokens.shape[1]):
            # Check if proposed token is in base model's top-k
            proposed_token = proposed_tokens[0, i]
            base_topk_tokens = base_topk[0, i, :]

            if proposed_token in base_topk_tokens:
                accepted_len = i + 1
            else:
                break

        return accepted_len, {
            "policy": self.name,
            "k": self.k,
            "accepted_len": accepted_len,
            "proposed_len": proposed_tokens.shape[1],
        }

    def get_info(self) -> Dict[str, Any]:
        """Get policy information."""
        return {
            "policy": self.name,
            "k": self.k,
        }


class TypicalAcceptancePolicy(AcceptancePolicy):
    """Accept tokens based on typical acceptance probability."""

    def __init__(self, p: float = 0.9):
        """
        Initialize typical acceptance policy.

        Args:
            p: Typical acceptance probability (0.0 to 1.0)
        """
        self.p = p
        self.name = "typical"

    def accept_tokens(
        self,
        proposed_tokens: torch.Tensor,
        base_tokens: torch.Tensor,
        proposed_logits: Optional[torch.Tensor] = None,
        base_logits: Optional[torch.Tensor] = None,
        **kwargs: Any,
    ) -> Tuple[int, Dict[str, Any]]:
        """Accept tokens based on typical acceptance probability."""
        if proposed_logits is None or base_logits is None:
            # Fallback to longest prefix if no logits available
            policy = LongestPrefixPolicy()
            return policy.accept_tokens(proposed_tokens, base_tokens)

        # Calculate typical acceptance probability
        torch.softmax(proposed_logits, dim=-1)
        base_probs = torch.softmax(base_logits, dim=-1)

        # Calculate typical acceptance for each position
        accepted_len = 0
        for i in range(proposed_tokens.shape[1]):
            # Get probability of proposed token in base model
            proposed_token = proposed_tokens[0, i]
            base_prob = base_probs[0, i, proposed_token]

            # Accept if probability is above typical threshold
            if base_prob >= self.p:
                accepted_len = i + 1
            else:
                break

        return accepted_len, {
            "policy": self.name,
            "p": self.p,
            "accepted_len": accepted_len,
            "proposed_len": proposed_tokens.shape[1],
            "min_probability": (
                float(
                    torch.min(
                        base_probs[0, :accepted_len, proposed_tokens[0, :accepted_len]]
                    )
                )
                if accepted_len > 0
                else 0.0
            ),
        }

    def get_info(self) -> Dict[str, Any]:
        """Get policy information."""
        return {
            "policy": self.name,
            "p": self.p,
        }


def create_policy(policy_name: str, **kwargs: Any) -> AcceptancePolicy:
    """
    Create an acceptance policy by name.

    Args:
        policy_name: Name of the policy to create
        **kwargs: Policy-specific parameters

    Returns:
        AcceptancePolicy instance

    Raises:
        ValueError: If policy_name is not recognized
    """
    policies = {
        "longest_prefix": LongestPrefixPolicy,
        "conf_threshold": lambda: ConfidenceThresholdPolicy(kwargs.get("tau", 0.5)),
        "topk_agree": lambda: TopKAgreementPolicy(kwargs.get("k", 5)),
        "typical": lambda: TypicalAcceptancePolicy(kwargs.get("p", 0.9)),
    }

    if policy_name not in policies:
        raise ValueError(
            f"Unknown policy: {policy_name}. Available: {list(policies.keys())}"
        )

    return policies[policy_name]()
